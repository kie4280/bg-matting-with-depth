{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intel depth.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP8PUmZHGt3f",
        "outputId": "6db47b4e-67a0-4a43-f5f1-be15a5266028"
      },
      "source": [
        "%cd /content/drive/MyDrive/research\n",
        "!git clone https://github.com/intel-isl/MiDaS.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/research\n",
            "Cloning into 'MiDaS'...\n",
            "remote: Enumerating objects: 250, done.\u001b[K\n",
            "remote: Counting objects: 100% (250/250), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 394 (delta 58), reused 202 (delta 37), pack-reused 144\u001b[K\n",
            "Receiving objects: 100% (394/394), 231.02 KiB | 2.69 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ealPtevBHFPA"
      },
      "source": [
        "%cd /content/drive/MyDrive/research/MiDaS/\n",
        "\n",
        "# this is the test code from the repository\n",
        "!python run.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl_BO0ydI_ac",
        "outputId": "c4a3396a-1051-4d0a-ad48-50cbc0604473"
      },
      "source": [
        "%cd /content/drive/MyDrive/research/MiDaS/\n",
        "\n",
        "# this is the custom code\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from torchvision.transforms import Compose\n",
        "from midas.midas_net import MidasNet\n",
        "from midas.midas_net_custom import MidasNet_small\n",
        "from midas.transforms import Resize, NormalizeImage, PrepareForNet\n",
        "\n",
        "def concat():\n",
        "\n",
        "    test_img = \"/home/kie/Downloads/Telegram Desktop/IMG_0649.MOV\"\n",
        "\n",
        "    folder = \"IMG_0655\"\n",
        "    # Create a VideoCapture object\n",
        "    cap = cv2.VideoCapture(\"/home/kie/Downloads/output/\" + folder + \"/com.mp4\")\n",
        "    orig = cv2.VideoCapture(test_img)\n",
        "\n",
        "    # Check if camera opened successfully\n",
        "    if (not cap.isOpened() or not orig.isOpened()):\n",
        "        print(\"Unable to read camera feed\")\n",
        "\n",
        "    # Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
        "    # We convert the resolutions from float to integer.\n",
        "    frame_width = 1920\n",
        "    frame_height = 1080\n",
        "    print(\"video shape\", frame_width, frame_height)\n",
        "\n",
        "    # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "    out = cv2.VideoWriter('outpy.avi', cv2.VideoWriter_fourcc(\n",
        "        'M', 'J', 'P', 'G'), 60, (frame_width, frame_height))\n",
        "    buf = np.zeros((frame_height, frame_width, 3), dtype='uint8')\n",
        "\n",
        "    while(True):\n",
        "        ret1, frame1 = cap.read()\n",
        "        ret2, frame2 = orig.read()\n",
        "\n",
        "        if ret1 == False and ret2 == False:\n",
        "            out.write(buf)\n",
        "            break\n",
        "        else:\n",
        "            if ret1:\n",
        "                frame = cv2.rotate(frame1, cv2.ROTATE_90_CLOCKWISE)\n",
        "                # print(frame.shape)\n",
        "                print(buf.shape)\n",
        "                np.copyto(buf[:1920, :1080, :], frame)\n",
        "                # print(buf)\n",
        "                # break\n",
        "            if ret2:\n",
        "                # frame = cv2.rotate(frame2, cv2.ROTATE_90_CLOCKWISE)\n",
        "                np.copyto(buf[:1920, 1080:, :], frame2)\n",
        "\n",
        "        out.write(buf)\n",
        "        # cv2.imshow('frame',buf)\n",
        "\n",
        "    # When everything done, release the video capture and video write objects\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    orig.release()\n",
        "\n",
        "    # Closes all the frames\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "def initialize(model_path, optimize=True):\n",
        "    \"\"\"Run MonoDepthNN to compute depth maps.\n",
        "\n",
        "    Args:\n",
        "        input_path (str): path to input folder\n",
        "        output_path (str): path to output folder\n",
        "        model_path (str): path to saved model\n",
        "    \"\"\"\n",
        "    print(\"initialize\")\n",
        "\n",
        "    # select device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"device: %s\" % device)\n",
        "   \n",
        "    model = MidasNet(model_path, non_negative=True)\n",
        "    net_w, net_h = 384, 384  \n",
        "    \n",
        "    transform = Compose(\n",
        "        [\n",
        "            Resize(\n",
        "                net_w,\n",
        "                net_h,\n",
        "                resize_target=None,\n",
        "                keep_aspect_ratio=True,\n",
        "                ensure_multiple_of=32,\n",
        "                resize_method=\"upper_bound\",\n",
        "                image_interpolation_method=cv2.INTER_CUBIC,\n",
        "            ),\n",
        "            NormalizeImage(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            PrepareForNet(),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    if optimize==True:\n",
        "        rand_example = torch.rand(1, 3, net_h, net_w)\n",
        "        model(rand_example)\n",
        "        traced_script_module = torch.jit.trace(model, rand_example)\n",
        "        model = traced_script_module\n",
        "    \n",
        "        if device == torch.device(\"cuda\"):\n",
        "            model = model.to(memory_format=torch.channels_last)  \n",
        "            model = model.half()\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    return model, transform\n",
        "\n",
        "   \n",
        "\n",
        "def computeDepth(model, transform):\n",
        "     # get input\n",
        "    img_names = glob.glob(os.path.join(input_path, \"*\"))\n",
        "    num_images = len(img_names)\n",
        "\n",
        "    # create output folder\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    print(\"start processing\")\n",
        "\n",
        "    for ind, img_name in enumerate(img_names):\n",
        "\n",
        "        print(\"  processing {} ({}/{})\".format(img_name, ind + 1, num_images))\n",
        "\n",
        "        # input\n",
        "\n",
        "        img = utils.read_image(img_name)\n",
        "        img_input = transform({\"image\": img})[\"image\"]\n",
        "\n",
        "        # compute\n",
        "        with torch.no_grad():\n",
        "            sample = torch.from_numpy(img_input).to(device).unsqueeze(0)\n",
        "            if optimize==True and device == torch.device(\"cuda\"):\n",
        "                sample = sample.to(memory_format=torch.channels_last)  \n",
        "                sample = sample.half()\n",
        "            prediction = model.forward(sample)\n",
        "            prediction = (\n",
        "                torch.nn.functional.interpolate(\n",
        "                    prediction.unsqueeze(1),\n",
        "                    size=img.shape[:2],\n",
        "                    mode=\"bicubic\",\n",
        "                    align_corners=False,\n",
        "                )\n",
        "                .squeeze()\n",
        "                .cpu()\n",
        "                .numpy()\n",
        "            )\n",
        "\n",
        "        # output\n",
        "        filename = os.path.join(\n",
        "            output_path, os.path.splitext(os.path.basename(img_name))[0]\n",
        "        )\n",
        "        utils.write_depth(filename, prediction, bits=2)\n",
        "\n",
        "    print(\"finished\")\n",
        "    \n",
        "\n",
        "\n",
        "if (__name__ == \"__main__\"):\n",
        "    concat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/research/MiDaS\n",
            "Unable to read camera feed\n",
            "video shape 1920 1080\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}